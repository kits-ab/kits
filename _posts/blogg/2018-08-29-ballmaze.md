---
layout: bloggpost
heading: Over-engineering a booth competition
image: secfest2018-4
authors:
 - mikaelwecksten
 - tobiaslans
 - williambernting
category: blogg
published: true
---
During Security Fest 2018 we decided to build a competition the only way we know how: by over-engineering it!
We started by buying a ball maze. We also recently saw that 8Bitdo had released their new SN30 controller and we wanted a excuse to buy one ... maybee we can control the ball maze with it? So of course we had to auto-**maze** the game and play it using a controller!

###### ![](/images/blogg/ballmaze1.jpg)![](/images/blogg/ballmaze2.jpg)![](/images/blogg/ballmaze3.jpg)

## Ball mazeing for dummies

We broke out the 3D-printer, modified some stepper stands (creative commons, made by  adamyelland [download drawing](https://www.thingiverse.com/thing:1938710)), bought some servos (Luxorparts S3003) and got to soldering!
We attached the whole thing to a Raspberry Pi 3 which in turn steered the servos and listened to the NS30 over bluetooth (by following [guide](https://core-electronics.com.au/tutorials/using-usb-and-bluetooth-controllers-with-python.html)).

At first we wanted to use the gyro function to steer how much the servos should move but for some reason we never got it to work.

So we moved on to using the sticks. Left stick for up/down, right one for left/right. It was not the most natural way to steer so the first couple of times playing most struggled slightly, just as intended!
The last piece of our over-engineering was how to time each race from start to either finish or failure.

We opted for a webcam that kept track of the ball as it moved through the maze, giving points for each zone cleared and ending the game when it lost sight of the ball.
Recognizing objects using computer vision is a somewhat mystified process. Similar to how a person who is not a programmer perceives how applications are made, even a programmer may find that they don't have a clue on what actually happens to "recognize" things using a camera and some code.
Recently, Google has launched something called TensorFlow, which somewhat realizes the most common conception. You take a picture (or video stream), feed it to a magical tool, and out comes data saying what it is, and perhaps also _where_ it is on the picture.
While TensorFlow grants this idea (somewhat), its usage truly pales in comparison for how generic the idea actually is.
OpenCV is an open source computer vision library, written mostly in C++, it effectively allows you, as a developer, to modify an image  as much as it let's you measure things. In the process of recognizing a red ball in an image, you may as well be.
• Modifying: Capturing the source picture, and shrinking it to a smaller resolution.

• Modifying: Removing all the Blue and Green in a picture, keeping only the Redness.

• Modifying: Replacing a range of redness with a single, solid, red color

• Measuring: Get all matching pixels where neighboring pixels are also red.

• Measuring: Finding the biggest source of red by applying regular programming arithmetics.
While the example above is intentionally convoluted, the reality is that _this_ is how you detect things. Any magical function that will instantly tell you what something is, is either A. Something like the above, B. An incredibly complex algorithm with thousands of patterns for objects that exist in real life, or C. A mixture of both.
Additionally, what you are actually dealing with when doing object detection, is a lot of math, creativity and a lot of helper utilities to get you going faster, thanks to a library like OpenCV.